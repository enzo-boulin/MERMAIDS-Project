{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from useful_func import *\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 40\n",
    "\n",
    "df = pd.read_csv('info_events.csv', index_col=0)\n",
    "df['Picked arrival'] = pd.to_datetime(df['Picked arrival'])\n",
    "df['file_start'] = pd.to_datetime(df['file_start'])\n",
    "diff = (df['Picked arrival']- df['file_start']) #temps entre le debut de l'enregistrement et l'arrivée du séisme.\n",
    "df['diff'] = diff.dt.total_seconds()\n",
    "df = df.sort_values(by='Picked arrival')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for dossier_actuel, sous_dossiers, fichiers in os.walk('data\\DonneesB23'):\n",
    "    if \"_MACOSX\" not in dossier_actuel:\n",
    "        for fichier in fichiers:\n",
    "            if '.DS_Store' not in fichier:\n",
    "                path = os.path.join(dossier_actuel, fichier)\n",
    "                y = np.fromfile(path, dtype=np.int32)\n",
    "                if len(y)/fs > 2*60*60 :\n",
    "                    all_files.append(path)\n",
    "del y\n",
    "noisy_files = []\n",
    "known_files = list(df['file'].unique())\n",
    "for file in all_files :\n",
    "    if file not in known_files :\n",
    "        noisy_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positives(files, events_time, demi_duree, n, fs=40, rd = True):\n",
    "\n",
    "    signal_tronque = []\n",
    "    signals = [ np.fromfile(file, dtype=np.int32) for file in files]\n",
    "\n",
    "    i = 0\n",
    "    while len(signal_tronque) < n :\n",
    "        shift = np.random.normal(0, demi_duree/100, 1)[0]\n",
    "        if not rd :\n",
    "            shift = 0\n",
    "        a = int(events_time[i] + shift - demi_duree)\n",
    "        b = int(events_time[i] + shift + demi_duree)\n",
    "\n",
    "        if a > 0 and b < len(signals[i])/fs :\n",
    "            y = signals[i][ a*fs : b*fs ]\n",
    "            signal_tronque.append(y)\n",
    "\n",
    "        i = (i + 1) % len(files)\n",
    "\n",
    "    return signal_tronque\n",
    "        \n",
    "\n",
    "\n",
    "def get_negatives(noisy_files, duree, nb_0, fs=40):\n",
    "    signals = [ np.fromfile(file, dtype=np.int32) for file in noisy_files]\n",
    "\n",
    "    X_0 = []\n",
    "    i = 0\n",
    "    while len(X_0) < nb_0 :\n",
    "        T = int(len(signals[i])/fs)\n",
    "        t = np.random.randint(T - duree)\n",
    "        y = signals[i][t*fs : t*fs + duree*fs]\n",
    "        X_0.append(y)\n",
    "            \n",
    "        i = (i + 1) % len(noisy_files)\n",
    "    return X_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demi_duree = 60*60 \n",
    "\n",
    "n = 500\n",
    "\n",
    "#on enlève les séismes * et S1\n",
    "mask = (df['Tag']!='S1') & (df['Tag']!='*') \n",
    "\n",
    "#20% pour le jeu de test, ne pas séparer après get_positive car le jeu de test sera biaisé\n",
    "mask_t = np.random.randint(0, 10, len(mask)) < 8\n",
    "files = df[ mask & mask_t]['file'].values\n",
    "events_time = df[ mask & mask_t]['diff'].to_numpy(np.int32)\n",
    "\n",
    "\n",
    "signal_tronque =  get_positives(files, events_time, demi_duree, n)\n",
    "\n",
    "print(n, 'positives')\n",
    "\n",
    "nb_0 = int(n*2)\n",
    "\n",
    "X_0 = get_negatives(noisy_files, 2*demi_duree, nb_0)\n",
    "\n",
    "print(nb_0, 'negatives')\n",
    "\n",
    "y_0 = np.zeros(len(X_0))\n",
    "y_1 = np.ones(len(signal_tronque))\n",
    "\n",
    "X = np.concatenate((X_0, signal_tronque))\n",
    "y = np.concatenate((y_0, y_1))\n",
    "\n",
    "\n",
    "del X_0, y_0, y_1, signal_tronque\n",
    "\n",
    "\n",
    "X = np.array(list(map(get_mov_rms, map(bp,  signal.decimate(X, 100)))))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rd = np.random.permutation(len(X))\n",
    "X_train = X[rd]\n",
    "y_train = y[rd]\n",
    "model = RandomForestClassifier(n_estimators=50, max_depth=20, criterion='gini', class_weight='balanced_subsample', verbose=0, n_jobs=-1, max_features='sqrt')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = df[ mask & (1-mask_t)]['file'].values\n",
    "events_time = df[ mask & (1-mask_t)]['diff'].to_numpy(np.int32)\n",
    "\n",
    "\n",
    "signal_tronque =  get_positives(files, events_time, demi_duree, len(files), rd = False)\n",
    "\n",
    "test = np.array(list(map(get_mov_rms, map(bp,  signal.decimate(signal_tronque, 100)))))\n",
    "res = model.predict(test)\n",
    "test_0 = get_negatives(noisy_files, 2*demi_duree, 3*len(files))\n",
    "test_0 = np.array(list(map(get_mov_rms, map(bp,  signal.decimate(test_0, 100)))))\n",
    "res_0 = model.predict(test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = res\n",
    "tn =  (1-res_0)\n",
    "fp = res_0\n",
    "fn = (1-res)\n",
    "print(f\"tp: {np.sum(tp)}\")\n",
    "print(f\"tn: {np.sum(tn)}\")\n",
    "print(f\"fp: {np.sum(fp)}\")\n",
    "print(f\"fn: {np.sum(fn)}\")\n",
    "acc = (np.sum(tp)+np.sum(tn))/(np.sum(tp)+np.sum(tn)+np.sum(fp)+np.sum(fn))\n",
    "print(f\"accuracy: {acc}\")\n",
    "precision = np.sum(tp)/(np.sum(tp)+np.sum(fp))\n",
    "recall = np.sum(tp)/(np.sum(tp)+np.sum(fn))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(f\"precision: {round(precision,2)}\")\n",
    "print(f\"recall: {round(recall,2)}\")\n",
    "print(f\"f1 score: {round(f1, 2)}\")\n",
    "p0 = (np.sum(tp)+np.sum(tn))/(np.sum(tp)+np.sum(tn)+np.sum(fp)+np.sum(fn))\n",
    "pe = ((np.sum(tp)+np.sum(fp))*(np.sum(tp)+np.sum(fn))+(np.sum(fn)+np.sum(tn))*(np.sum(fp)+np.sum(tn)))/((np.sum(tp)+np.sum(tn)+np.sum(fp)+np.sum(fn))**2)\n",
    "kappa = (p0-pe)/(1-pe)\n",
    "print(f\"kappa: {round(kappa, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = np.array([[sum(tn), sum(fp)],\n",
    "                        [sum(fn), sum(tp)]])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['Prédit négatif', 'Prédit positif'],\n",
    "            yticklabels=['Vrai négatif', 'Vrai positif'],\n",
    "            annot_kws={\"fontsize\": 40})  \n",
    "plt.xlabel('Valeurs prédites', fontsize=12) \n",
    "plt.ylabel('Valeurs réelles', fontsize=12)  \n",
    "plt.title('Matrice de confusion', fontsize=20) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ne regarde quasiment que l'arrivée de l'onde S\n",
    "plt.plot(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To visualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duree = 2*demi_duree\n",
    "file = df['file'].iloc[i]\n",
    "y = np.fromfile(file, dtype=np.int32)\n",
    "T = len(y) \n",
    "intervalle = 60*60*fs \n",
    "nb_echant = int(T/intervalle)\n",
    "print(nb_echant, 'samples to test')\n",
    "X_t = []\n",
    "for j in range(nb_echant) :\n",
    "    if len(y[intervalle*j : intervalle*j + (duree)*fs]) == (duree)*fs :\n",
    "        X_t.append(y[intervalle*j : intervalle*j + (duree)*fs])\n",
    "\n",
    "\n",
    "X_t = np.array(X_t)\n",
    "print(X_t.shape)\n",
    "\n",
    "X_t = list(map(get_mov_rms, map(bp, signal.decimate(X_t, 100))))\n",
    "\n",
    "predictions = model.predict(X_t)\n",
    "indices = np.where(predictions == 1)[0]\n",
    "print(len(indices), 'events detected')\n",
    "y_d = bp(signal.decimate(y, 100))\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(y_d)\n",
    "\n",
    "for j in indices :\n",
    "    plt.axvline(intervalle*j/100+(duree//2)*fs/100, color='r', linestyle='--', label='detected event')\n",
    "plt.axvline(df['diff'].iloc[i]*fs/100, color='g', linestyle='--', label='known event')\n",
    "\n",
    "plt.xlabel('Temps (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title(f'seismic event detection on {i}th file')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "i = (i+1)%len(df['file'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If the model is strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('big_random_forest.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
